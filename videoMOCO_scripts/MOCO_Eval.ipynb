{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from temporal_transform import TemporalRandomCrop, TemporalCenterCrop\n",
    "from resnet3d import generate_model\n",
    "from ucf101 import get_ucf_dataset\n",
    "from hmdb51 import get_hmdb_dataset\n",
    "from logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(show = True, html_output = True)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "frame_size = logger.config_dict['frame_resize']\n",
    "spatial_transform = transforms.Compose([transforms.Resize((frame_size, frame_size)), \n",
    "                                         transforms.ToTensor(), normalize])\n",
    "logger.log(\"Frames resized to {}x{}\".format(frame_size, frame_size))\n",
    "\n",
    "sampling_method_str = logger.config_dict['sampling_method']\n",
    "if \"rand\" in sampling_method_str:\n",
    "    crop_size = int(sampling_method_str.replace(\"rand\", \"\"))\n",
    "    sampling_method = TemporalRandomCrop(size = crop_size)\n",
    "    logger.log(\"Sampling strategy selecting {} consecutives frames from a random index\".format(\n",
    "      crop_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = os.path.join(logger.data_folder, \n",
    "                          logger.config_dict['video_folder'], logger.config_dict['frame_folder'])\n",
    "#video_path = \"../data/hmdb51_videos/jpg\"\n",
    "annotation_path = logger.get_data_file(logger.config_dict['annotation_file'])\n",
    "batch_size  = logger.config_dict['batch_size']\n",
    "num_workers = logger.config_dict['num_workers']\n",
    "dataset_type = logger.config_dict['dataset_type']\n",
    "\n",
    "if dataset_type == \"ucf101\":\n",
    "    train_dataset = get_ucf_dataset(video_path, annotation_path, \"training\", sampling_method, \n",
    "                                    spatial_transform, temporal_transform = \"None\",\n",
    "                                    stack_clip = True, is_moco_transform = False, \n",
    "                                    apply_same_per_clip = True)\n",
    "    test_dataset = get_ucf_dataset(video_path, annotation_path, \"validation\", sampling_method, \n",
    "                                   spatial_transform, temporal_transform = \"None\",\n",
    "                                   stack_clip = True, is_moco_transform = False, \n",
    "                                   apply_same_per_clip = True)\n",
    "elif dataset_type == \"hmdb51\":\n",
    "    train_dataset = get_hmdb_dataset(video_path, annotation_path, \"training\", sampling_method, \n",
    "                                     spatial_transform, temporal_transform = \"None\",\n",
    "                                     stack_clip = True, is_moco_transform = False, \n",
    "                                     apply_same_per_clip = True)\n",
    "    test_dataset = get_hmdb_dataset(video_path, annotation_path, \"validation\", sampling_method, \n",
    "                                    spatial_transform, temporal_transform = \"None\",\n",
    "                                    stack_clip = True, is_moco_transform = False, \n",
    "                                    apply_same_per_clip = True)\n",
    "\n",
    "    \n",
    "logger.log(\"Batch size {}\".format(batch_size))\n",
    "train_loader  = DataLoader(train_dataset, batch_size = batch_size, shuffle = False, drop_last = False, \n",
    "                           num_workers = num_workers)\n",
    "logger.log(\"{} Train data loaded with {} clips\".format(dataset_type.upper(), len(train_dataset)))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, drop_last = False,\n",
    "                         num_workers = num_workers)\n",
    "logger.log(\"{} Test data loaded with {} clips\".format(dataset_type.upper(), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = logger.config_dict['base_convnet']\n",
    "num_classes = logger.config_dict['num_classes']\n",
    "model = generate_model(model_depth = 18, n_classes = num_classes)\n",
    "logger.log(\"Model {} 3D simCLR loaded {}\".format(base_model, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_epoch = logger.config_dict['model_checkpoint_epoch']\n",
    "checkpoint_file  = logger.config_dict['model_checkpoint_file']\n",
    "checkpoint = torch.load(logger.get_model_file(checkpoint_file), map_location=\"cpu\")\n",
    "logger.log(\"Loading MOCO model weights at epoch {} from {}\".format(checkpoint_epoch, checkpoint_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "for k in list(state_dict.keys()):\n",
    "    # retain only encoder_q up to before the embedding layer\n",
    "    if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):\n",
    "    # remove prefix\n",
    "        state_dict[k[len(\"module.encoder_q.\"):]] = state_dict[k]\n",
    "\n",
    "    # delete renamed or unused k\n",
    "    del state_dict[k]\n",
    "\n",
    "msg = model.load_state_dict(state_dict, strict=False)\n",
    "assert set(msg.missing_keys) == {\"fc.weight\", \"fc.bias\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if name not in ['fc.weight', 'fc.bias']:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Identity()\n",
    "gpu_avail = torch.cuda.is_available()\n",
    "logger.log(\"GPU available: {}\".format(gpu_avail))\n",
    "if gpu_avail:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "logger.log(\"Generating MOCO features from training data ...\")\n",
    "X_train_feature = []\n",
    "y_train = []\n",
    "\n",
    "for i, (inputs, labels) in tqdm(enumerate(train_loader)):\n",
    "    if gpu_avail:\n",
    "        inputs = inputs.cuda()\n",
    "            \n",
    "    features = model(inputs)\n",
    "    X_train_feature.extend(features.detach().cpu().numpy())\n",
    "    y_train.extend(labels.numpy())\n",
    "\n",
    "    \n",
    "X_train_feature = np.array(X_train_feature)\n",
    "logger.log(\"Train features of shape: {}\".format(X_train_feature.shape), show_time = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "logger.log(\"Generating MOCO features from testing data ...\")\n",
    "X_test_feature = []\n",
    "y_test = []\n",
    "\n",
    "for i, (inputs, labels) in tqdm(enumerate(test_loader)):\n",
    "    if gpu_avail:\n",
    "        inputs = inputs.cuda()\n",
    "            \n",
    "    features = model(inputs)\n",
    "    X_test_feature.extend(features.detach().cpu().numpy())\n",
    "    y_test.extend(labels.numpy())\n",
    "\n",
    "X_test_feature = np.array(X_test_feature)\n",
    "logger.log(\"Test features of shape: {}\".format(X_test_feature.shape), show_time = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=1000, solver='lbfgs', C=1.0, n_jobs = -1)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train_feature)\n",
    "\n",
    "logger.log(\"Start training LogisticRegression on MOCO features ...\")\n",
    "clf.fit(scaler.transform(X_train_feature), y_train)\n",
    "logger.log(\"Finished training\", show_time = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.log(\"MOCO feature evaluation on {}\".format(dataset_type))\n",
    "logger.log(\"Train score: {:.3f}\".format(clf.score(scaler.transform(X_train_feature), y_train)))\n",
    "logger.log(\"Test score: {:.3f}\".format(clf.score(scaler.transform(X_test_feature), y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
